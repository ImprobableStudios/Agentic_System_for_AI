#!/bin/bash
# Model Configuration for Systems with 4GB or more of VRAM

# Primary general-purpose model
# PRIMARY_MODEL: phi-2.7b (approx. 1.8GB, Q4_K)
PRIMARY_MODEL="phi:2.7b:Q4_K"

# Code-specialized model
# CODE_MODEL: codellama-7b-instruct (approx. 3.5GB, Q2_K)
CODE_MODEL="codellama:7b-instruct:Q2_K"

# Embedding model for vector operations
# EMBEDDING_MODEL: BAAI/bge-small-en-v1.5 (approx. 0.4GB)
EMBEDDING_MODEL="BAAI/bge-small-en-v1.5"

# Reranking model for search result optimization
# RERANKING_MODEL: BAAI/bge-small-en-v1.5 (approx. 0.4GB)
RERANKING_MODEL="BAAI/bge-small-en-v1.5"

# Small general-purpose model for quick tasks
# SMALL_MODEL: phi-2.7b (approx. 1.8GB, Q4_K)
SMALL_MODEL="phi:2.7b:Q4_K"

# Additional models array for bulk operations
MODELS_TO_PULL=(
    "$PRIMARY_MODEL"
    "$CODE_MODEL"
    "$EMBEDDING_MODEL"
    "$RERANKING_MODEL"
    "$SMALL_MODEL"
)
